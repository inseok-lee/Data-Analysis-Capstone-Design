# 딥러닝 기법을 활용한 노래 가사 감정분류 (Data Analysis Capstone Design 2022-1)
* 소프트웨어융합학과 이인석

## 1. 과제 개요

### 가. 과제 선정 배경 및 필요성
감정이란 어떤 현상이나 일에 대해 느끼는 기분, 더 세부적으로 설명하면 어떤 외부 자극에 대해서 보이는 주관적인 느낌을 의미한다. 사람들은 대화, 글쓰기 등 다양한 방식으로 감정을 표현한다. 그중 본 프로젝트는 에서는 노래 가사로 표현된 감정에 초점을 맞추어 감정 분류 모델 구현을 제안한다. 실제로 음악을 감상하는 과정에 있어서 가사는 감상자의 음악 선택 기준의 중요한 요소 중 한가지로 작용한다. 특히 슬픔 정서적 상황에 놓여 있다면 가사가 가지는 인지적 메시지는 더 큰 영향을 준다. 하지만 멜론, 플로, 지니 뮤직 등의 인기 음원 사이트들은 노래 가사보다는 장르나 분위기, 아티스트, 인기순위 등의 정보를 통한 분류와 추천을 제공하는 경우가 많다. 따라서 본 프로젝트에서는 이러한 기존 관점에서 벗어나 ‘가사’라는 구성요소에 중점을 프로젝트를 수행한다. 데이터 수집과 전처리를 진행한 후 우선적으로 노래 가사의 감정 라벨링을 위해 Word2vec을 활용한 감정사전 구축을 수행하고 이후 4가지 딥러닝 감정분류기를 구현한다. 마지막으로 모델 간 성능 비교와 분석을 통해 결론을 도출한다.감정이란 어떤 현상이나 일에 대해 느끼는 기분, 더 세부적으로 설명하면 어떤 외부 자극에 대해서 보이는 주관적인 느낌을 의미한다. 사람들은 대화, 글쓰기 등 다양한 방식으로 감정을 표현한다. 그중 본 프로젝트는 에서는 노래 가사로 표현된 감정에 초점을 맞추어 감정 분류 모델 구현을 제안한다. 실제로 음악을 감상하는 과정에 있어서 가사는 감상자의 음악 선택 기준의 중요한 요소 중 한가지로 작용한다. 특히 슬픔 정서적 상황에 놓여 있다면 가사가 가지는 인지적 메시지는 더 큰 영향을 준다. 하지만 멜론, 플로, 지니 뮤직 등의 인기 음원 사이트들은 노래 가사보다는 장르나 분위기, 아티스트, 인기순위 등의 정보를 통한 분류와 추천을 제공하는 경우가 많다. 따라서 본 프로젝트에서는 이러한 기존 관점에서 벗어나 ‘가사’라는 구성요소에 중점을 프로젝트를 수행한다. 데이터 수집과 전처리를 진행한 후 우선적으로 노래 가사의 감정 라벨링을 위해 Word2vec을 활용한 감정사전 구축을 수행하고 이후 4가지 딥러닝 감정분류기를 구현한다. 마지막으로 모델 간 성능 비교와 분석을 통해 결론을 도출한다.

### 나. 과제 주요내용
- 데이터 수집 및 전처리
- 감정 분류 기준 결정
- 토큰화 및 감정사전 구축/라벨링
- 4가지 딥러닝 모델 구현(LSTM, Bi-LSTM, GRU, CNN)
- 평가 및 모델별 비교

## 2. 과제의 목표

### 가. 최종결과물의 목표 (정량적/정성적 목표 설정)

1) 딥러닝 모델의 성능의 정확도를 80% 이상을 목표로 한다.

2) 모델 별 성능 비교 분석

### 나. 최종결과물의 세부내용 및 구성
![image](https://github.com/inseok-lee/Data-Analysis-Capstone-Design/assets/92963189/bd7c60e8-fc31-444d-8d6b-d007f0f85a0a)

1) LSTM
 Long Short-Term Memory, 전통적인 RNN의 단점(장기 의존성 문제)을 보완하기 위해 게이트 개념을 추가한 방식이다. 은닉층의 메모리셀에 입력 게이트, 망각 게이트, 출력 게이트를 추가하여 불필요한 기억 지우고 기억해야 할 것들을 결정한다. 긴 시퀀스의 입력을 처리하는데 탁월한 성능을 보이며 셀 상태 정보를 가지고 있다.
 LSTM 모델은 python의 Keras 라이브러리를 활용하여 구현하였으며, 모델 구현 후 지속적인 모델 구조 및 파라미터 변경을 통해 성능 개선을 진행하였다. 그 결과 가장 성능이 좋은 모델의 구조 및 파라미터는 다음과 같다. 해당 모델의 경우 다중 모델과 이진 모델의 최적 파라미터 설정 값이 같다.

다중, 이진 분류 모델: Embedding_dim = 100, hidden_unit = 128, epochs = 50, batch_size = 16, EarlyStopping 옵션의 patience =15

과적합 방지를 위해 Dropout = 0.3을 적용하였으며 출력층에는 분류를 수행을 위해 활성함수로 softmax를 적용하였다.

2) Bi-LSTM
 Bidirectional LSTM, 두 개의 LSTM으로 이루어져 있는 모델이다. 하나의 LSTM은 input을 forward 방향으로 받고, 다른 하나는 backward 방향에서 받기 때문에 이전 정보와 이후 정보를 모두 담고 있다.
 Bi-LSTM 모델 역시 python의 Keras 라이브러리를 활용하여 구현하였으며, 모델 구현 후 지속적인 모델 구조 및 파라미터 변경을 통해 성능 개선을 진행하였다. 그 결과 가장 성능이 좋은 모델의 구조 및 파라미터는 다음과 같다.

다중 분류 모델: Embedding_dim = 100, hidden_unit = 50, epochs = 20, batch_size = 80, EarlyStopping 옵션의 patience =10
이진 분류 모델: Embedding_dim = 100, hidden_unit = 50, epochs = 20, batch_size = 70, EarlyStopping 옵션의 patience =10

해당 모델 역시 출력층에는 분류를 수행을 위해 활성함수로 softmax를 적용하였다.

3) GRU
Gated Recurrent Unit, LSTM보다 게이트의 개수가 1개 적어진 2개의 게이트(업데이트 게이트, 리셋 게이트)가 존재한다. 또한 LSTM과 다르게 셀 상태에 대한 정보가 없다. LSTM보다 간소화된 구조를 가지고 있지만 비슷한 학습성능을 보인다, 특히 학습 데이터가 적은 경우 LSTM보다 좋은 성능을 보이기도 한다.
GRU 모델은 python의 PyTorch 라이브러리를 활용하여 구현하였으며, 모델 구현 후 지속적인 모델 구조 및 파라미터 변경을 통해 성능 개선을 진행하였다. 그 결과 가장 성능이 좋은 모델의 구조 및 파라미터는 다음과 같다. GRU 모델의 경우도 다중분류와 이진분류의 최적 파라미터 설정이 같다.

다중, 이진 분류 모델: Embedding_dim = 128, hidden_unit = 128, epochs = 30, batch_size = 16, Learning Rate = 0.001

과적합 방지를 위해 Dropout = 0.2을 적용하였다.

4) CNN
Convolutional Neural Network, 시각적 영상을 분석하는 데 주로 사용되는 모델로 자연어 처리의 경우 이미지 처리에 사용되는 2D CNN과 달리 1D CNN 사용한다. 커널의 너비를 문장 행렬에서의 임베딩 벡터의 차원과 동일하게 설정하여 설계한다.
CNN 모델은 python의 Keras 라이브러리를 활용하여 구현하였으며, 모델 구현 후 지속적인 모델 구조 및 파라미터 변경을 통해 성능 개선을 진행하였다. 그 결과 가장 성능이 좋은 모델의 구조 및 파라미터는 다음과 같다.

다중 분류 모델: Embedding_dim = 300, hidden_unit = 128, kernel_num = 256, kernel_size = 3
이진 분류 모델: Embedding_dim = 256, hidden_unit = 128, kernel_num = 10, kernel_size = 3, hidden_unit = 128

과적합 방지를 위해 Dropout = 0.3을 적용하였다.


## 3. 기대효과 및 활용방안

 감성사전 구축과 라벨링, 모델학습 과정에서 모두 두려움, 분노, 슬픔 3가지 부정적인 감정을 구분하고 분류하는 하는 것이 어려움이 있었다. 결과적으로 이러한 원인으로 인해 다중분류 모델에서는 4가지 딥러닝 모두 성능이 좋지 않았으며, 가장 좋은 모델의 성능은 정확도 66%, F1 score 69% 수준이었다. 이진분류로 분류 방식을 바꾼 결과 4가지 딥러닝 모델 모두 성능이 크게 향상됨을 확인할 수 있었다. 결과적으로 다중분류, 이진분류 모두 양방향 정보를 활용하여 분류하는 Bi-LSTM 모델이 가장 뛰어난 성능을 보였다. 
 추후 더욱 세밀한 감성사전 구축과 데이터 정제가 이루어진다면 더 향상된 성능의 분류기를 구현해낼 수 있을 것이라 기대하고 다중분류 역시 더 성공적으로 진행해볼 수 있을 것이라 생각한다. 또한, 기존 음악 분류 시스템에 해당 가사 감정분류 모델이 결합된다면 더 다양한 음악적 요소들이 고려된 분류 및 추천시스템이 만들어질 수 있을 것이라 기대한다.


## 4. 수행방법

### 가. 과제수행을 위한 도구적 방법

Python, Colab, Pytorch

### 나. 과제수행 계획

## Schedule
| Contents | March | April |  May  | June  |   Progress   |
|----------|-------|-------|-------|-------|--------------|
|  데이터 수집  |   O   |       |       |       |     Link1    |
|  관련 기법 학습  |   O   |   O    |       |       |     Link2    |
|  모델 구축 및 수정  |       |      |   O   |   O    |     Link3    |
|  성능 비교  |       |       |      |   O    |     Link4    |
|  보고서 작성  |       |       |       |   O   |     Link5    |


## Results



## Conclusion

 한국어 감정 분류를 진행하는 것이 처음 계획하고 생각했던 것보다 훨씬 까다롭고 어려운 과정이라는 것을 느꼈다. 특히, 감성사전 구축에 있어서 관련 없는 단어를 삭제하는 과정이나 자체적으로 기준을 세워서 감정 라벨링을 진행하는 과정 등에서 많은 난관과 어려움으로 인해 시간을 많이 소모하게 되어서 아쉬움이 남는다. 하지만, 기존에 잘 구축되어 있는 데이터셋이 아니라 데이터의 수집부터 전처리, 라벨링 과정까지 모두 경험해볼 수 있는 기회가 되어서 모델 학습 전 데이터 준비과정에 대해 많이 배울 수 있었다. 딥러닝 모델 구현 및 학습 과정 역시 초반에 정확도의 수준이 너무 떨어지고 성능 개선이 잘 이루어지지 않아 고민과 걱정이 많았지만 결론적으로 다중분류와 이진분류 모델을 모두 경험해볼 수 있었고 다양한 성능 개선 방법을 찾아보고 공부하게 되는 계기가 되었다. 해당 프로젝트가 종료된 후에도 자연어 처리와 감정분류, 딥러닝 모델 구현에 대해 더 많이 공부해서 더 발전된 모델을 구현해보자 하는 목표가 생겼다.

## Reports
* Upload or link (e.g. Google Drive files with share setting)
* Midterm: [Report](Reports/Midterm.pdf)
* Final: [Report](Reports/Final.pdf), [Demo video](Reports/Demo.mp4)
